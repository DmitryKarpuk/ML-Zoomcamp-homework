{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset saved into the folder data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0  yes        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1  yes        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2  yes        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3  yes        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4  yes        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/AER_credit_card_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the target variable by mapping `yes` to 1 and `no` to 0. \n",
    "* Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` funciton for that with `random_state=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.card = (df.card == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.card.values\n",
    "y_val = df_val.card.values\n",
    "y_test = df_test.card.values\n",
    "\n",
    "del df_train['card']\n",
    "del df_val['card']\n",
    "del df_test['card']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score and compute AUC with the `card` variable.\n",
    "* Use the training dataset for that.\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['expenditure']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- `reports`\n",
    "- `dependents`\n",
    "- `active`\n",
    "- `share`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best roc_auc with  share\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "rc_features = ['reports', 'dependents', 'active', 'share']\n",
    "rc_list = [roc_auc_score(y_train, df_train[f]) if roc_auc_score(y_train, df_train[f]) > 0.5\n",
    "                             else roc_auc_score(y_train, -df_train[f]) for f in rc_features]\n",
    "print('Best roc_auc with ', rc_features[rc_list.index(max(rc_list))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer : share**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, use these columns only:\n",
    "\n",
    "```\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "```\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"reports\", \"age\", \"income\", \"share\", \"expenditure\",\n",
    "            \"dependents\", \"months\", \"majorcards\", \"active\",\n",
    "             \"owner\", \"selfemp\"]\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train[features].to_dict('records')\n",
    "X_train = dv.fit_transform(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.615\n",
    "- 0.515\n",
    "- 0.715\n",
    "- 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = df_val[features].to_dict('records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(roc_auc_score(y_val, model.predict(X_val)), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer : 0.995**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them\n",
    "\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.1\n",
    "* 0.3\n",
    "* 0.6\n",
    "* 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.0, 1, 0.01)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "for t in thresholds:\n",
    "    prob = model.predict_proba(X_val)[:, 1]\n",
    "    pred =  (prob >= t)\n",
    "    precision_scores.append(precision_score(y_val, pred))\n",
    "    recall_scores.append(recall_score(y_val, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersects = thresholds[(np.array(precision_scores) - np.array(recall_scores)) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.lineplot(data=pd.DataFrame({'precision':precision_scores, \n",
    "                'recall':recall_scores}, index=thresholds))\n",
    "plt.axvline(intersects[0], c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26, 0.27, 0.28, 0.29])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer : 0.3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "F1 = 2 * P * R / (P + R)\n",
    "\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- 0.4\n",
    "- 0.6\n",
    "- 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bset thresholds for f1 score:  0.42\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.0, 1, 0.01)\n",
    "f1_scores = []\n",
    "for t in thresholds:\n",
    "    prob = model.predict_proba(X_val)[:, 1]\n",
    "    pred =  (prob >= t)\n",
    "    f1_scores.append(f1_score(y_val, pred))\n",
    "best_thr = thresholds[f1_scores.index(max(f1_scores))]\n",
    "print('Bset thresholds for f1 score: ', best_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer : 0.42**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "- 0.003\n",
    "- 0.014\n",
    "- 0.09\n",
    "- 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_full_train = df_full_train.card.values\n",
    "full_train_dict = df_full_train[features].reset_index(drop=True).to_dict('records')\n",
    "X_full_train = dv.transform(full_train_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99418605, 0.99411765, 0.99433465, 0.99961079, 1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "auc_scores = np.array([])\n",
    "for train_idx, val_idx in kf.split(X_full_train):\n",
    "    X_train = X_full_train[train_idx]\n",
    "    X_val = X_full_train[val_idx]\n",
    "    y_train = y_full_train[train_idx]\n",
    "    y_val = y_full_train[val_idx]\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prob = model.predict_proba(X_val)[:, 1]\n",
    "    score = roc_auc_score(y_val, y_prob)\n",
    "    auc_scores = np.append(auc_scores, score)\n",
    "auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027434713804377724"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Deviation\n",
    "np.sqrt(np.mean((auc_scores - auc_scores.mean())**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer : 0.003**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean scores:  [0.992, 0.995, 0.996, 0.996]\n",
      "Standard deviation [0.006, 0.004, 0.003, 0.003]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "C_list = [0.01, 0.1, 1, 10]\n",
    "mean_auc_scores = []\n",
    "std_mean_auc = []\n",
    "n_splits = kf.get_n_splits()\n",
    "for C in C_list:\n",
    "    k_mean_score = np.array([])\n",
    "    k_std = 0\n",
    "    for train_idx, val_idx in kf.split(X_full_train):\n",
    "        X_train = X_full_train[train_idx]\n",
    "        X_val = X_full_train[val_idx]\n",
    "        y_train = y_full_train[train_idx]\n",
    "        y_val = y_full_train[val_idx]\n",
    "        model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_val)[:, 1]\n",
    "        score = roc_auc_score(y_val, y_prob)\n",
    "        k_mean_score = np.append(k_mean_score, round(score, 3))\n",
    "    k_std = round(np.std(k_mean_score), 3)\n",
    "    mean_auc_scores.append(round(k_mean_score.mean(), 3))\n",
    "    std_mean_auc.append(k_std)\n",
    "print('Mean scores: ', mean_auc_scores)\n",
    "print('Standard deviation', std_mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer : 1**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6268ec3b7bda0430df9e46aed4ea38b000c75aff742e0bbd747c4b0dc23f8a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
